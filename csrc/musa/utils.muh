#pragma once

#include "../extensions.h"
#include "torch_musa/csrc/aten/utils/Utils.h"

#define CHECK_MUSA(x)                                                          \
  AT_ASSERTM(at::musa::is_musa(x), #x " must be MUSA tensor")
#define CHECK_INPUT(x) AT_ASSERTM(x, "Input mismatch")

__device__ __inline__ at::Half __shfl_up_sync(const unsigned mask,
                                              const at::Half var,
                                              const unsigned int delta) {
  return __shfl_up_sync(mask, var.operator __half(), delta);
}

__device__ __inline__ at::Half __shfl_down_sync(const unsigned mask,
                                                const at::Half var,
                                                const unsigned int delta) {
  return __shfl_down_sync(mask, var.operator __half(), delta);
}

__device__ __inline__ at::Half __shfl_sync(const unsigned mask,
                                           const at::Half var,
                                           const int delta) {
  return __shfl_sync(mask, var.operator __half(), delta);
}

__device__ __inline__ at::Half __shfl_up(const at::Half var,
                                         const unsigned int delta) {
  return __shfl_up(var.operator __half(), delta);
}

__device__ __inline__ at::Half __shfl_down(const at::Half var,
                                           const unsigned int delta) {
  return __shfl_down(var.operator __half(), delta);
}

__device__ __inline__ at::Half
__shfl(const at::Half var, const int delta) {
  return __shfl(var.operator __half(), delta);
}

#define SHFL_UP_SYNC __shfl_up_sync
#define SHFL_DOWN_SYNC __shfl_down_sync
#define SHFL_SYNC __shfl_sync

/////////////////////////////////////////////////////////////////////////////////////////////////

/**
 * log2 computation, what's the
 * difference between the below codes and
 * log2_up/down codes?
 */
template <typename value_t>
__device__ __host__ __forceinline__ value_t clz(value_t x) {
  for (int i = 31; i >= 0; --i) {
    if ((1 << i) & x)
      return 31 - i;
  }
  return 32;
}

template <typename value_t>
__device__ __host__ __forceinline__ value_t find_log2(value_t x) {
  int a = int(31 - clz(x));
  a += (x & (x - 1)) != 0; // Round up, add 1 if not a power of 2.
  return a;
}

/**
 * Find divisor, using find_log2
 */
__device__ __host__ __forceinline__ void find_divisor(
    uint32_t& mul,
    uint32_t& shr,
    uint32_t denom) {
  if ((denom & (denom - 1)) == 0) {
    mul = 1;
    shr = find_log2(denom);
  } else {
    uint32_t p = 31 + find_log2(denom);
    unsigned m =
        unsigned(((1ull << p) + unsigned(denom) - 1) / unsigned(denom));

    mul = m;
    shr = p;
  }
}

/**
 * Find quotient and remainder using device-side intrinsics
 */
__device__ __host__ __forceinline__ void fast_divmod(
    uint32_t& quo,
    uint32_t& rem,
    uint32_t src,
    uint32_t div,
    uint32_t mul,
    uint32_t shr) {
  quo = (uint32_t)(((uint64_t)src * mul) >> shr);

  // The remainder.
  rem = src - (quo * div);
}

/////////////////////////////////////////////////////////////////////////////////////////////////

/// Object to encapsulate the fast division+modulus operation.
///
/// This object precomputes two values used to accelerate the computation and is
/// best used when the divisor is a grid-invariant. In this case, it may be
/// computed in host code and marshalled along other kernel arguments using the
/// 'Params' pattern.
///
/// Example:
///
///
///   int quotient, remainder, dividend, divisor;
///
///   FastDivmod divmod(divisor);
///
///   divmod(quotient, remainder, dividend);
///
///   // quotient = (dividend / divisor)
///   // remainder = (dividend % divisor)
///
struct FastDivmod {
  uint32_t divisor;
  uint32_t multiplier;
  uint32_t shift_right;

  /// Construct the FastDivmod object, in host code ideally.
  ///
  /// This precomputes some values based on the divisor and is computationally
  /// expensive.

  __device__ __host__ __forceinline__ FastDivmod()
      : divisor(0), multiplier(0), shift_right(0) {}

  __device__ __host__ __forceinline__ FastDivmod(uint32_t divisor_)
      : divisor(divisor_) {
    find_divisor(multiplier, shift_right, divisor);
  }

  /// Computes integer division and modulus using precomputed values. This is
  /// computationally inexpensive.
  __device__ __host__ __forceinline__ void operator()(
      uint32_t& quotient,
      uint32_t& remainder,
      uint32_t dividend) const {
    fast_divmod(
        quotient, remainder, dividend, divisor, multiplier, shift_right);
  }

  /// Computes integer division and modulus using precomputed values. This is
  /// computationally inexpensive.
  ///
  /// Simply returns the quotient
  __device__ __host__ __forceinline__ uint32_t
  divmod(uint32_t& remainder, uint32_t dividend) const {
    uint32_t quotient;
    fast_divmod(
        quotient, remainder, dividend, divisor, multiplier, shift_right);
    return quotient;
  }

  __device__ __host__ __forceinline__ uint32_t div(uint32_t dividend) const {
    uint32_t quotient, remainder;
    fast_divmod(
        quotient, remainder, dividend, divisor, multiplier, shift_right);
    return quotient;
  }
};
